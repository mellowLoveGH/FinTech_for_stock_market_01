{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "713034a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict HK stocks according to US stocks\n",
    "    # there is jet-lag between US stocks and HK stocks\n",
    "    # US stock markets have much influence over HK stock markets\n",
    "    # exploit the information from US stock markets to predict HK stock markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "63d9475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages needed\n",
    "import yfinance as yf #!pip install yfinance\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b1e51cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data by ticker-name, start-time & end-time\n",
    "def get_df_data(ticker_name=\"AAPL\", start_time=\"2022-01-01\", end_time=\"2022-10-09\"):\n",
    "  df_data = yf.download(tickers=ticker_name, start=start_time, end=end_time) \n",
    "  #df_data.head()\n",
    "  return df_data\n",
    "\n",
    "# calculate the daily return by (current_index - previous_index) / previous_index\n",
    "def calculate_daily_return(df_data, OHLC_index=\"Close\"):\n",
    "  name1 = OHLC_index+\"_previous\"\n",
    "  df_data[name1] = df_data[OHLC_index].shift(1)\n",
    "  name2 = OHLC_index+\"_delta\"\n",
    "  df_data[name2] = df_data[OHLC_index] - df_data[name1]\n",
    "  name3 = OHLC_index+\"_return\"\n",
    "  df_data[name3] = df_data[name2] / df_data[name1]\n",
    "  del df_data[name1]\n",
    "  del df_data[name2]\n",
    "  new_feature = name3\n",
    "  return df_data #, new_feature\n",
    "\n",
    "# calculate the daily change of points & volumes\n",
    "    # by (current_index - previous_index) / previous_index\n",
    "    # by (current_volume - previous_volume) / previous_volume\n",
    "def calculate_daily_change(df_data):\n",
    "  # , OHLC_index=\"Close\"\n",
    "  df_data = calculate_daily_return(df_data, \"Close\")\n",
    "  df_data = calculate_daily_return(df_data, \"Volume\")\n",
    "  return df_data #, new_feature\n",
    "\n",
    "# convert the time to be string type: yyyy-mm-dd\n",
    "def get_ymt_date(df_data):\n",
    "  df_data[\"ymd_time\"] = df_data.index\n",
    "  df_data[\"ymd_time\"] = df_data[\"ymd_time\"].astype(str)\n",
    "  df_data[\"ymd_time\"] = df_data[\"ymd_time\"].str.slice(0,10)\n",
    "  return df_data\n",
    "\n",
    "# dict type: key - time, value - daily return\n",
    "def get_date_return(df_data):\n",
    "  return_list = list(df_data[\"Close_return\"])\n",
    "  time_list = list(df_data[\"ymd_time\"])\n",
    "  time_return_dic = {}\n",
    "  ii = 0\n",
    "  while ii<len(return_list):\n",
    "    time_return_dic[ time_list[ii] ] = return_list[ii]\n",
    "    \"\"\"if return_list[ii]>0:\n",
    "      time_return_dic[ time_list[ii] ] = 1\n",
    "    else:\n",
    "      time_return_dic[ time_list[ii] ] = 0\"\"\"\n",
    "    ii = ii + 1\n",
    "  return time_return_dic\n",
    "\n",
    "# get useful features and pack as dict-type\n",
    "    # key: date, value:\n",
    "def get_date_features(df_data, features=[\"Close_return\", \"Volume_return\"]):\n",
    "    time_list = list(df_data[\"ymd_time\"])\n",
    "    values_list = []\n",
    "    L = len(df_data)\n",
    "    for ii in range(L):\n",
    "        fv = []\n",
    "        for fn in features:\n",
    "            v = df_data.iloc[ii][fn]\n",
    "            fv.append(v)\n",
    "        values_list.append( fv )\n",
    "    time_return_dic = {}\n",
    "    ii = 0\n",
    "    while ii<L:\n",
    "        time_return_dic[ time_list[ii] ] = values_list[ii]\n",
    "        ii = ii + 1\n",
    "    return time_return_dic\n",
    "\n",
    "# compare 2 string-type dates, \n",
    "  # for example: '2022-01-01' -> 20220101, '2022-10-10' -> 20221010,\n",
    "def compare_date_str(date_str1, date_str2):\n",
    "  num1 = date_str1[0:4]+date_str1[5:7]+date_str1[8:10]\n",
    "  num1 = int(num1)\n",
    "  num2 = date_str2[0:4]+date_str2[5:7]+date_str2[8:10]\n",
    "  num2 = int(num2)\n",
    "  if num1>num2:\n",
    "    return 1\n",
    "  elif num1<num2:\n",
    "    return -1\n",
    "  return 0\n",
    "\n",
    "# 3 US stock indexes: Nasdaq, DJI, SP500, 1 HK index: HSI\n",
    "# get their data for certain year\n",
    "# close points -> moving average close points, parameter: nn\n",
    "# calculate the daily return based on the MA close points\n",
    "# get the date-return dic\n",
    "def get_useful_data(tn, st, et, nn, features=[\"Close_return\", \"Volume_return\"]):\n",
    "  stock_index = get_df_data(ticker_name=tn, start_time=st, end_time=et)\n",
    "  stock_index['SMA'+str(nn)] = stock_index['Close'].rolling(nn).mean() # moving average, smoothening function\n",
    "  stock_index['Close'] = stock_index['SMA'+str(nn)] # moving average, smoothening function\n",
    "  del stock_index['SMA'+str(nn)] # \n",
    "  stock_index = calculate_daily_change(stock_index)\n",
    "  stock_index = get_ymt_date(stock_index)\n",
    "  time_return = get_date_features(stock_index, features)\n",
    "  return stock_index, time_return\n",
    "\n",
    "# match US stocks with HK stock by time, because there is jet-lag between HK time & US time\n",
    "def US_HK_stock_signal(year = 2022, nn = 5):\n",
    "  st, et = str(year)+\"-01-01\", str(year)+\"-12-31\"\n",
    "  # ^IXIC, ^DJI, ^GSPC\n",
    "  nasdaq_df, nasdaq_time_return = get_date_return_dic(\"^IXIC\", st, et, nn)\n",
    "  dowjones_df, dowjones_time_return = get_date_return_dic(\"^DJI\", st, et, nn)\n",
    "  sp500_df, sp500_time_return = get_date_return_dic(\"^GSPC\", st, et, nn)\n",
    "\n",
    "  # ^HSI\n",
    "  hsi_df, hsi_time_return = get_date_return_dic(\"^HSI\", st, et, nn)  \n",
    "  \n",
    "  # \n",
    "  hk_us_stock_signal = []\n",
    "\n",
    "  for k, v in sorted(hsi_time_return.items()):\n",
    "    date_str = k\n",
    "    rise_fall_signal = v\n",
    "    for pk, pv in sorted(sp500_time_return.items(), reverse=True):\n",
    "      if compare_date_str(k, pk)==1:\n",
    "        v1 = sp500_time_return[pk]\n",
    "        v2 = dowjones_time_return[pk]\n",
    "        v3 = nasdaq_time_return[pk]\n",
    "        #print(k, v, pk, v1, v2, v3)\n",
    "        hk_us_stock_signal.append( (k, v, pk, v1, v2, v3) )\n",
    "        break\n",
    "  return hk_us_stock_signal\n",
    "\n",
    "# filter signals according to HK stock rise/fall\n",
    "def US_HK_info(hk_us_stock_signal, hk_s, us_stock_num):\n",
    "  tmp_list = []\n",
    "  for it in hk_us_stock_signal:\n",
    "    hkt, hk_signal, ust, us_signal1, us_signal2, us_signal3 = it\n",
    "    hk_signal = rise_fall_judge(hk_signal)\n",
    "    us_signal1 = rise_fall_judge(us_signal1)\n",
    "    us_signal2 = rise_fall_judge(us_signal2)\n",
    "    us_signal3 = rise_fall_judge(us_signal3)\n",
    "    #\n",
    "    if hk_signal==hk_s and sum( [us_signal1, us_signal2, us_signal3] ) == us_stock_num:\n",
    "      tmp_list.append( it )\n",
    "  return tmp_list\n",
    "\n",
    "# rise -> 1, fall -> 0\n",
    "def rise_fall_judge(point):\n",
    "  if point > 0:\n",
    "    return 1\n",
    "  return 0\n",
    "\n",
    "# match US stocks with HK stock by time, because there is jet-lag between HK time & US time\n",
    "def stocks_signal(refer_list=[\"^IXIC\", \"^DJI\", \"^GSPC\"], target=\"^HSI\", st=\"2022-01-01\", et=\"2022-12-31\", nn=5, features=[\"Close_return\", \"Volume_return\"]):\n",
    "  # reference list\n",
    "  refer_dic_list = []\n",
    "  for it in refer_list:\n",
    "    _, tmp = get_useful_data(it, st, et, nn, features)\n",
    "    refer_dic_list.append( tmp )\n",
    "  # target\n",
    "  _, target_dic = get_useful_data(target, st, et, nn, features) # [\"Close_return\"]\n",
    "  # integrate references & target\n",
    "  hk_us_stock_signal = []\n",
    "  for k, v in sorted(target_dic.items()):\n",
    "    date_str = k\n",
    "    rise_fall_signal = v\n",
    "    for pk, pv in sorted(refer_dic_list[0].items(), reverse=True):\n",
    "      if compare_date_str(k, pk)==1:\n",
    "        vs = []\n",
    "        for rd in refer_dic_list:\n",
    "          vs.append( rd[pk] )\n",
    "        #print(k, v, pk, vs)\n",
    "        hk_us_stock_signal.append( (k, v, pk, vs) )\n",
    "        break\n",
    "  return hk_us_stock_signal\n",
    "\n",
    "# list of lists -> dataframe\n",
    "def lists_to_dataframe(hk_us_stock_signal, refer_list, target):\n",
    "  tmp_list = []\n",
    "  L = 0\n",
    "  for it in hk_us_stock_signal[ : ]:\n",
    "    hkt, hk_hsi, ust, vs = it\n",
    "    # flatten list of lists to be list \n",
    "    vs = np.array(vs)\n",
    "    vs = vs.reshape(-1)\n",
    "    vs = list(vs)\n",
    "    L = len(vs)\n",
    "    sub_list = []\n",
    "    sub_list.append( hkt )\n",
    "    sub_list += hk_hsi\n",
    "    sub_list.append( ust )\n",
    "    sub_list += vs\n",
    "    tmp_list.append( sub_list )\n",
    "  cols = [\"HKT\"]\n",
    "  cols.append( target+\"_close\" )\n",
    "  cols.append( target+\"_volume\" )\n",
    "  cols.append( \"UST\" )\n",
    "  for it in refer_list:\n",
    "    cols.append( it+\"_close\" )\n",
    "    cols.append( it+\"_volume\" )\n",
    "  #print( len(cols), len(tmp_list[0]) )\n",
    "  assert len(cols)==len(tmp_list[0])\n",
    "  df_data = pd.DataFrame(tmp_list, columns=cols)\n",
    "  return df_data\n",
    "\n",
    "# scale list\n",
    "def scale_list_values(vs):\n",
    "  tmp = []\n",
    "  for v in vs:\n",
    "    tmp.append( v*100 )\n",
    "  return tmp\n",
    "\n",
    "# get data-sets for training & testing models from dataframe\n",
    "def dataframe_Xy(df_data):\n",
    "    X, y = [], []\n",
    "    for i in range(len(df_data)):\n",
    "        row = list( df_data.iloc[i] )\n",
    "        target_daily_return = row[1]\n",
    "        refer_values = row[4:]\n",
    "        #\n",
    "        if math.isnan(target_daily_return):\n",
    "            continue\n",
    "        fg = False\n",
    "        for v in refer_values:\n",
    "            if math.isnan(v):\n",
    "                fg = True\n",
    "                break\n",
    "        if fg:\n",
    "            continue\n",
    "        #\n",
    "        X.append( scale_list_values(refer_values) )\n",
    "        if target_daily_return>0:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3ae6126f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "business days:  213 rise vs fall:  86 125\n",
      "sampled business days:  172 rise vs fall:  86 86\n"
     ]
    }
   ],
   "source": [
    "### prepare data to fit models\n",
    "nn = 1\n",
    "dataset_xy = []\n",
    "refer_list=[\"^IXIC\", \"AAPL\", \"GOOGL\", \"AMZN\", \"BABA\", \"PDD\", \"JD\", \"MPNGY\", \"TME\", \"BIDU\"] # \"^IXIC\", \"^DJI\", \"^GSPC\"\n",
    "target=\"9988.HK\" # 0700.HK, ^HSI, 0005.HK:滙豐控股, 1299.HK:友邦保險, 0700.HK:騰訊控股, 9988.HK:阿⾥巴巴, 3690.HK:美團\n",
    "st, et = str(year)+\"-01-01\", str(year)+\"-12-31\"\n",
    "st, et = \"2022-01-01\", \"2022-11-15\"\n",
    "features=[\"Close_return\", \"Volume_return\"]\n",
    "\n",
    "hk_us_stock_signal = stocks_signal(refer_list, target, st, et, nn, features)\n",
    "df_data = lists_to_dataframe(hk_us_stock_signal, refer_list, target)\n",
    "df_data\n",
    "\n",
    "# balance the positive and negative samples\n",
    "positive_df = df_data[ df_data[target+\"_close\"]>0 ].copy()\n",
    "negative_df = df_data[ df_data[target+\"_close\"]<0 ].copy()\n",
    "positive_df = positive_df.dropna()\n",
    "negative_df = negative_df.dropna()\n",
    "print( \"business days: \", len(df_data), \"rise vs fall: \", len(positive_df), len(negative_df) )\n",
    "sample_number = min( len(positive_df), len(negative_df) )\n",
    "X_pos_data, y_pos_data = dataframe_Xy(positive_df.sample(n = sample_number))\n",
    "X_neg_data, y_neg_data = dataframe_Xy(negative_df.sample(n = sample_number))\n",
    "X_data = X_pos_data + X_neg_data\n",
    "y_data = y_pos_data + y_neg_data\n",
    "print( \"sampled business days: \", len(X_data), \"rise vs fall: \", len(X_pos_data), len(X_neg_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c6ebd484",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  129 129\n",
      "testing data:  43 43\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.73      0.68        22\n",
      "           1       0.67      0.57      0.62        21\n",
      "\n",
      "    accuracy                           0.65        43\n",
      "   macro avg       0.65      0.65      0.65        43\n",
      "weighted avg       0.65      0.65      0.65        43\n",
      "\n",
      "LR 0.6511627906976745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.77      0.71        22\n",
      "           1       0.71      0.57      0.63        21\n",
      "\n",
      "    accuracy                           0.67        43\n",
      "   macro avg       0.68      0.67      0.67        43\n",
      "weighted avg       0.68      0.67      0.67        43\n",
      "\n",
      "SVM 0.6744186046511628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75        22\n",
      "           1       0.76      0.62      0.68        21\n",
      "\n",
      "    accuracy                           0.72        43\n",
      "   macro avg       0.73      0.72      0.72        43\n",
      "weighted avg       0.73      0.72      0.72        43\n",
      "\n",
      "RF 0.7209302325581395\n"
     ]
    }
   ],
   "source": [
    "### data-set split and train models\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.25, random_state=0, shuffle=True)\n",
    "print( \"training data: \", len(X_train), len(y_train) )\n",
    "print( \"testing data: \", len(X_test), len(y_test) )\n",
    "print()\n",
    "\n",
    "# LR\n",
    "LR1 = LogisticRegression()\n",
    "LR1.fit(X_train, y_train)\n",
    "y_pred = LR1.predict(X_test)\n",
    "score = LR1.score(X_test, y_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"LR\", score)\n",
    "\n",
    "\n",
    "# SVM\n",
    "SVM1 = svm.SVC(kernel='linear', probability=True)  # solver='lbfgs', , max_iter=1000 * 1000 * 20\n",
    "SVM1.fit(X_train, y_train)\n",
    "y_pred = SVM1.predict(X_test)\n",
    "score = SVM1.score(X_test, y_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"SVM\", score)\n",
    "\n",
    "\n",
    "# RF\n",
    "RM1=RandomForestClassifier(n_estimators=100)\n",
    "RM1.fit(X_train, y_train)\n",
    "y_pred = RM1.predict(X_test)\n",
    "score = RM1.score(X_test, y_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"RF\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5b4b5df6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "date_time: 2022-11-14 00:00:00 ^IXIC -1.122552735683811 -1.122552735683811\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "date_time: 2022-11-14 00:00:00 AAPL -0.9485625904429829 -0.9485625904429829\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "date_time: 2022-11-14 00:00:00 GOOGL -0.7364450647212569 -0.7364450647212569\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "date_time: 2022-11-14 00:00:00 AMZN -2.281975425008139 -2.281975425008139\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "date_time: 2022-11-14 00:00:00 BABA 0.7913031150936856 0.7913031150936856\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "date_time: 2022-11-14 00:00:00 PDD 0.32218331311664744 0.32218331311664744\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "date_time: 2022-11-14 00:00:00 JD 3.9239692560194337 3.9239692560194337\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "date_time: 2022-11-14 00:00:00 MPNGY -3.497348757739115 -3.497348757739115\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "date_time: 2022-11-14 00:00:00 TME 0.9070286448309121 0.9070286448309121\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "date_time: 2022-11-14 00:00:00 BIDU 2.224455493108685 2.224455493108685\n",
      "lastest_data of US stock market info:  [-1.122552735683811, -1.122552735683811, -0.9485625904429829, -0.9485625904429829, -0.7364450647212569, -0.7364450647212569, -2.281975425008139, -2.281975425008139, 0.7913031150936856, 0.7913031150936856, 0.32218331311664744, 0.32218331311664744, 3.9239692560194337, 3.9239692560194337, -3.497348757739115, -3.497348757739115, 0.9070286448309121, 0.9070286448309121, 2.224455493108685, 2.224455493108685]\n",
      "LR predict today:  [1] [[0.047358 0.952642]]\n",
      "SVM predict today:  [1] [[0.28149364 0.71850636]]\n",
      "RF predict today:  [1] [[0.36 0.64]]\n"
     ]
    }
   ],
   "source": [
    "# get latest US stock data to predict HK stock\n",
    "df_reference = pd.DataFrame()\n",
    "year = 2022\n",
    "st, et = str(year)+\"-01-01\", str(year)+\"-12-31\"\n",
    "#refer_list=[\"^IXIC\", \"AAPL\", \"GOOGL\", \"AMZN\", \"BABA\", \"PDD\", \"JD\", \"MPNGY\", \"TME\", \"BIDU\"] # \"^IXIC\", \"^DJI\", \"^GSPC\"\n",
    "#target=\"9988.HK\" # 0700.HK, ^HSI, 0005.HK:滙豐控股, 1299.HK:友邦保險, 0700.HK:騰訊控股, 9988.HK:阿⾥巴巴, 3690.HK:美團\n",
    "lastest_data = []\n",
    "lastest_day = -1\n",
    "for tn in refer_list:\n",
    "    tmp_df = get_df_data(tn, st, et)\n",
    "    tmp_df = calculate_daily_change(tmp_df)\n",
    "    #tmp_df = tmp_df[ ['Close', 'Close_return'] ]\n",
    "    #df_reference[tn+\"_Close\"] = tmp_df[ 'Close' ]\n",
    "    df_reference[tn+\"_Close_return\"] = tmp_df[ 'Close_return' ]\n",
    "    df_reference[tn+\"_Volume_return\"] = tmp_df[ 'Volume_return' ]\n",
    "    date_time = list(tmp_df.index)[lastest_day]\n",
    "    close_point = list(tmp_df[ 'Close_return' ])[lastest_day]\n",
    "    volume_point = list(tmp_df[ 'Close_return' ])[lastest_day]\n",
    "    lastest_data.append( close_point )\n",
    "    lastest_data.append( volume_point )\n",
    "    print(\"date_time:\", date_time, tn, close_point*100, volume_point*100)\n",
    "df_reference\n",
    "lastest_data = scale_list_values(lastest_data) # scale the data as the procedure of training data\n",
    "print(\"lastest_data of US stock market info: \", lastest_data)\n",
    "\n",
    "#\n",
    "rise_or_fall = LR1.predict([lastest_data])\n",
    "prob = LR1.predict_proba([lastest_data])\n",
    "print( \"LR predict today: \", rise_or_fall, prob )\n",
    "\n",
    "rise_or_fall = SVM1.predict([lastest_data])\n",
    "prob = SVM1.predict_proba([lastest_data])\n",
    "print( \"SVM predict today: \", rise_or_fall, prob )\n",
    "\n",
    "rise_or_fall = RM1.predict([lastest_data])\n",
    "prob = RM1.predict_proba([lastest_data])\n",
    "print( \"RF predict today: \", rise_or_fall, prob )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "38f220aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
