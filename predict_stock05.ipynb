{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b46e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict HK stocks according to US stocks\n",
    "    # there is jet-lag between US stocks and HK stocks\n",
    "    # US stock markets have much influence over HK stock markets\n",
    "    # exploit the information from US stock markets to predict HK stock markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9807e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base data design: incremental data\n",
    "    # base data: one year ago - last business day (namely, one year until current business day)\n",
    "        # base data: training + testing (75% : 25%)\n",
    "# predict current business day\n",
    "\n",
    "# 1. it means every day the base-data should be updated, \n",
    "        # remove the data of the business day of one year ago\n",
    "        # add  the data of the latest business day\n",
    "    # for example, \n",
    "        # today is 2022-11-18, \n",
    "        # base-data should be (2021-11-18 ~ 2022-11-17) \n",
    "        # use the base-data to train & test model, \n",
    "        # then the model predict today/current business day: rise or fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "abfa2a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance\n",
    "import yfinance as yf # https://pypi.org/project/yfinance/\n",
    "import math\n",
    "### the meaning of prediction about stock market\n",
    "from numpy.core.numeric import ones_like\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "caada68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_data_once():\n",
    "    us_stock_ticker = [\"^IXIC\", \"AAPL\", \"GOOGL\", \"AMZN\", \"MSFT\", \"BABA\", \"PDD\", \"JD\", \"NTES\", \"BIDU\", \"MPNGY\", \"NIO\", \"TCOM\", \"LI\", \"ZTO\", \"TME\", \"XPEV\"]\n",
    "    hk_stock_ticker = [\"9988.HK\", \"3690.HK\", \"0700.HK\", \"9618.HK\", \"0981.HK\", \"9999.HK\", \"1810.HK\", \"1024.HK\", \"9888.HK\", \"2015.HK\", \"9866.HK\"]\n",
    "    ticker_list = us_stock_ticker+hk_stock_ticker\n",
    "    df_dic = {}\n",
    "    start_time=\"2020-01-01\"\n",
    "    end_time=\"2022-12-31\"\n",
    "    for tn in ticker_list:\n",
    "        df_data = yf.download(tickers=tn, start=start_time, end=end_time) \n",
    "        df_dic[tn] = df_data\n",
    "    return df_dic\n",
    "\n",
    "def search_stock(df_dic, tn, st, et):\n",
    "    tmp_df = df_dic[tn].copy()\n",
    "    tmp_df['ymd_time'] = tmp_df.index\n",
    "    tmp_df[\"ymd_time\"] = tmp_df[\"ymd_time\"].astype(str)\n",
    "    tmp_df[\"ymd_time\"] = tmp_df[\"ymd_time\"].str.slice(0,10)\n",
    "    tmp_df[\"date_num\"] = tmp_df[\"ymd_time\"].str.slice(0,4) + tmp_df[\"ymd_time\"].str.slice(5,7) + tmp_df[\"ymd_time\"].str.slice(8,10)\n",
    "    tmp_df[\"date_num\"] = tmp_df[\"date_num\"].astype(int)\n",
    "    stn = int(st[:4] + st[5:7] + st[8:10])\n",
    "    etn = int(et[:4] + et[5:7] + et[8:10])\n",
    "    #print(stn, etn)\n",
    "    tmp_df = tmp_df[ tmp_df[\"date_num\"]>=stn]\n",
    "    tmp_df = tmp_df[ tmp_df[\"date_num\"]<etn]\n",
    "    del tmp_df[\"ymd_time\"]\n",
    "    del tmp_df[\"date_num\"]\n",
    "    return tmp_df\n",
    "\n",
    "df_dic = None\n",
    "if df_dic is None:\n",
    "    df_dic = get_data_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a4ba4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data by ticker-name, start-time & end-time\n",
    "def get_df_data(ticker_name=\"AAPL\", start_time=\"2022-01-01\", end_time=\"2022-10-09\"):\n",
    "  #df_data = yf.download(tickers=ticker_name, start=start_time, end=end_time) \n",
    "  df_data = search_stock(df_dic, ticker_name, start_time, end_time)\n",
    "  return df_data\n",
    "\n",
    "# calculate the daily return by (current_index - previous_index) / previous_index\n",
    "def calculate_daily_return(df_data, OHLC_index=\"Close\"):\n",
    "  name1 = OHLC_index+\"_previous\"\n",
    "  df_data[name1] = df_data[OHLC_index].shift(1)\n",
    "  name2 = OHLC_index+\"_delta\"\n",
    "  df_data[name2] = df_data[OHLC_index] - df_data[name1]\n",
    "  name3 = OHLC_index+\"_return\"\n",
    "  df_data[name3] = df_data[name2] / df_data[name1]\n",
    "  del df_data[name1]\n",
    "  del df_data[name2]\n",
    "  new_feature = name3\n",
    "  return df_data #, new_feature\n",
    "\n",
    "# calculate the daily change of points & volumes\n",
    "    # by (current_index - previous_index) / previous_index\n",
    "    # by (current_volume - previous_volume) / previous_volume\n",
    "def calculate_daily_change(df_data):\n",
    "  # , OHLC_index=\"Close\"\n",
    "  df_data = calculate_daily_return(df_data, \"Close\")\n",
    "  df_data = calculate_daily_return(df_data, \"Volume\")\n",
    "  return df_data #, new_feature\n",
    "\n",
    "# convert the time to be string type: yyyy-mm-dd\n",
    "def get_ymt_date(df_data):\n",
    "  df_data[\"ymd_time\"] = df_data.index\n",
    "  df_data[\"ymd_time\"] = df_data[\"ymd_time\"].astype(str)\n",
    "  df_data[\"ymd_time\"] = df_data[\"ymd_time\"].str.slice(0,10)\n",
    "  return df_data\n",
    "\n",
    "# convert dataframe to dict-type data\n",
    "    # key: date time\n",
    "    # value: features such as Close_return & Volume_return\n",
    "def date_features_dict(df_data, features=[\"ymd_time\", \"Close_return\", \"Volume_return\"]):\n",
    "    tmp_df = df_data[features].copy()\n",
    "    date_list = list(tmp_df[\"ymd_time\"])\n",
    "    close_return_list = list(tmp_df[\"Close_return\"])\n",
    "    volume_return_list = list(tmp_df[\"Volume_return\"])\n",
    "    dic = {}\n",
    "    ii = 0\n",
    "    while ii<len(tmp_df):\n",
    "        d, cr, vr = date_list[ii], close_return_list[ii], volume_return_list[ii]\n",
    "        dic[d] = [cr, vr]\n",
    "        ii += 1\n",
    "    return dic\n",
    "\n",
    "# get latest US stock data to predict HK stock\n",
    "def get_multiple_stocks(refer_list, st, et):\n",
    "    df_reference = pd.DataFrame()\n",
    "    for tn in refer_list:\n",
    "        tmp_df = get_df_data(tn, st, et)\n",
    "        tmp_df = calculate_daily_change(tmp_df)\n",
    "        tmp_df = get_ymt_date(tmp_df)\n",
    "        df_reference['ymd_time'] = tmp_df['ymd_time']\n",
    "        df_reference[tn+\"_Close_return\"] = tmp_df[ 'Close_return' ]\n",
    "        df_reference[tn+\"_Volume_return\"] = tmp_df[ 'Volume_return' ]\n",
    "    return df_reference\n",
    "\n",
    "# get label\n",
    "def date_label(df_target, features):\n",
    "    tmp_df = df_target[features].copy()\n",
    "    date_list = list(tmp_df[\"ymd_time\"])\n",
    "    close_return_list = list(tmp_df[\"Close_return\"])\n",
    "    dic = {}\n",
    "    ii = 0\n",
    "    while ii<len(tmp_df):\n",
    "        d, cr = date_list[ii], close_return_list[ii]\n",
    "        if cr>0:\n",
    "            dic[d] = 1\n",
    "        else:\n",
    "            dic[d] = 0\n",
    "        ii += 1\n",
    "    return dic\n",
    "\n",
    "# get features\n",
    "def date_features(df_reference, refer_list):\n",
    "    new_refer_list = [\"ymd_time\"]\n",
    "    for tn in refer_list:\n",
    "        new_refer_list.append(tn + \"_Close_return\")\n",
    "        new_refer_list.append(tn + \"_Volume_return\")\n",
    "    tmp_df = df_reference[new_refer_list].copy()\n",
    "    dic = {}\n",
    "    ii = 0\n",
    "    while ii<len(tmp_df):\n",
    "        row = tmp_df.iloc[ii]\n",
    "        ymd_time = row['ymd_time']\n",
    "        features = []\n",
    "        for tn in new_refer_list[1:]:\n",
    "            features.append( row[tn] )\n",
    "        dic[ymd_time] = features\n",
    "        ii += 1\n",
    "    return dic\n",
    "\n",
    "# get date before today by n days\n",
    "def previous_date(current, days_num=1):\n",
    "    current = datetime.datetime.strptime(current, \"%Y-%m-%d\").date() # %H:%M:%S\n",
    "    previous = current - datetime.timedelta(days=days_num)\n",
    "    return str(previous)\n",
    "\n",
    "# get date after today by n days\n",
    "def next_date(current, days_num=1):\n",
    "    current = datetime.datetime.strptime(current, \"%Y-%m-%d\").date() # %H:%M:%S\n",
    "    next_date = current + datetime.timedelta(days=days_num)\n",
    "    return str(next_date)\n",
    "\n",
    "# search previous business day in US stock market\n",
    "    # according to business day in HK stock market\n",
    "def last_US_day(HK_day, us_business_days):\n",
    "    for days_num in range(1, 30):\n",
    "        US_day = previous_date(HK_day, days_num)\n",
    "        if US_day in us_business_days:\n",
    "            return US_day\n",
    "    return HK_day\n",
    "\n",
    "# \n",
    "def merge_features_labels(us_dic, hk_dic, refer_list, target):\n",
    "    xy_data = []\n",
    "    for HK_day, label in hk_dic.items():\n",
    "        US_day = last_US_day(HK_day, us_business_days)\n",
    "        if HK_day == US_day:\n",
    "            continue\n",
    "        features = us_dic[US_day]\n",
    "        row = [HK_day, label, US_day] + features\n",
    "        xy_data.append( row )\n",
    "    # X, y = [], []\n",
    "    cols = []\n",
    "    cols.append(target+\"_date\")\n",
    "    cols.append(\"label\")\n",
    "    cols.append(\"refer_date\")\n",
    "    for tn in refer_list:\n",
    "        cols.append(tn + \"_Close_return\")\n",
    "        cols.append(tn + \"_Volume_return\")\n",
    "    df = pd.DataFrame(xy_data, columns = cols)\n",
    "    return df\n",
    "\n",
    "# get data-sets for training & testing models from dataframe\n",
    "def dataframe_xy(df_data):\n",
    "    X, y = [], []\n",
    "    for i in range(len(df_data)):\n",
    "        row = list( df_data.iloc[i] )\n",
    "        [HK_day, label, US_day] = row[:3]\n",
    "        features = row[3:]\n",
    "        #\n",
    "        fg = False\n",
    "        for v in features:\n",
    "            if math.isnan(v):\n",
    "                fg = True\n",
    "                break\n",
    "        if fg:\n",
    "            continue\n",
    "        #\n",
    "        X.append( scale_list_values(features) )\n",
    "        y.append(label)\n",
    "    return X, y\n",
    "\n",
    "# sample data for training & testing model\n",
    "def sample_dataset(df_data, ran_seed, sample_number=-1):\n",
    "    # balance the positive and negative samples\n",
    "    positive_df = df_data[ df_data['label']==1 ].copy()\n",
    "    negative_df = df_data[ df_data['label']==0 ].copy()\n",
    "    positive_df = positive_df.dropna()\n",
    "    negative_df = negative_df.dropna()\n",
    "    #print( \"business days: \", len(df_data), \"rise vs fall: \", len(positive_df), len(negative_df) )\n",
    "    if sample_number==-1:\n",
    "        sample_number = min( len(positive_df), len(negative_df) )\n",
    "    X_pos_data, y_pos_data = dataframe_xy(positive_df.sample(n=sample_number, random_state=ran_seed))\n",
    "    X_neg_data, y_neg_data = dataframe_xy(negative_df.sample(n=sample_number, random_state=ran_seed))\n",
    "    X_data = X_pos_data + X_neg_data\n",
    "    y_data = y_pos_data + y_neg_data\n",
    "    #print( \"sampled business days: \", len(X_data), \"rise vs fall: \", len(X_pos_data), len(X_neg_data) )\n",
    "    return X_data, y_data\n",
    "\n",
    "# data-set split and train models\n",
    "def split_dataset(X_data, y_data, ran_seed):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.25, random_state=ran_seed, shuffle=True)\n",
    "    #print( \"training data: \", len(X_train), len(y_train) )\n",
    "    #print( \"testing data: \", len(X_test), len(y_test) )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# train LR model\n",
    "def train_LR_model(X_train, X_test, y_train, y_test):    \n",
    "    \"\"\"# LR\n",
    "    LR1 = LogisticRegression()\n",
    "    LR1.fit(X_train, y_train)\n",
    "    y_pred = LR1.predict(X_test)\n",
    "    score = LR1.score(X_test, y_test)\n",
    "    #print(classification_report(y_test, y_pred))\n",
    "    #print(\"LR\", score)\"\"\"\n",
    "    LR1, score = None, 0\n",
    "    for i in range(10):\n",
    "        rf, s = train_RF_model(X_train, X_test, y_train, y_test, i)\n",
    "        if s>score:\n",
    "            LR1, score = rf, s\n",
    "    \n",
    "    return LR1, score\n",
    "\n",
    "# train RF model\n",
    "def train_RF_model(X_train, X_test, y_train, y_test, ran_seed):\n",
    "    # RF\n",
    "    RF1=RandomForestClassifier(n_estimators=100, random_state=ran_seed)\n",
    "    RF1.fit(X_train, y_train)\n",
    "    y_pred = RF1.predict(X_test)\n",
    "    score = RF1.score(X_test, y_test)\n",
    "    #print(classification_report(y_test, y_pred))\n",
    "    #print(\"RF\", score)\n",
    "    return RF1, score\n",
    "\n",
    "\n",
    "#\n",
    "def get_features(st, et, refer_list, ind):\n",
    "    df_reference = get_multiple_stocks(refer_list, st, et)\n",
    "    features = []\n",
    "    for tn in refer_list:\n",
    "        date_time = list(df_reference.index)[ind]\n",
    "        close_point = list(df_reference[ tn+\"_Close_return\" ])[ind]\n",
    "        volume_point = list(df_reference[tn+\"_Volume_return\" ])[ind]\n",
    "        print(\"date_time:\", date_time, tn, close_point*100, volume_point*100)\n",
    "        features.append( close_point )\n",
    "        features.append( volume_point )\n",
    "    return features\n",
    "\n",
    "#\n",
    "def get_features_update(st, et, refer_list, which_date):\n",
    "    df_reference = get_multiple_stocks(refer_list, st, et)\n",
    "    df_reference = df_reference[ df_reference['ymd_time']==which_date ]\n",
    "    #print(df_reference)\n",
    "    ind = -1\n",
    "    features = []\n",
    "    for tn in refer_list:\n",
    "        date_time = list(df_reference.index)[ind]\n",
    "        close_point = list(df_reference[ tn+\"_Close_return\" ])[ind]\n",
    "        volume_point = list(df_reference[tn+\"_Volume_return\" ])[ind]\n",
    "        print(\"date_time:\", date_time, tn, close_point*100, volume_point*100)\n",
    "        features.append( close_point )\n",
    "        features.append( volume_point )\n",
    "    return features\n",
    "\n",
    "# \n",
    "def search_movement(target, prediction_date_HK):\n",
    "    dt1, dt2 = previous_date(prediction_date_HK, 10), next_date(prediction_date_HK, 10)\n",
    "    df_data = search_stock(df_dic, target, dt1, dt2)\n",
    "    df_data = calculate_daily_change(df_data)\n",
    "    df_data = get_ymt_date(df_data)\n",
    "    df_data = df_data[df_data['ymd_time']==prediction_date_HK]\n",
    "    Close_return = df_data.iloc[-1]['Close_return']\n",
    "    if Close_return>0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375f7c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "tmp_stock = get_df_data('9988.HK', \"2022-01-01\", \"2022-12-31\")\n",
    "tmp_stock = calculate_daily_change(tmp_stock)\n",
    "tmp_stock = get_ymt_date(tmp_stock)\n",
    "hk_date_list = list(tmp_stock['ymd_time'])\n",
    "\n",
    "tmp_stock = get_df_data('AAPL', \"2021-01-01\", \"2022-12-31\")\n",
    "tmp_stock = calculate_daily_change(tmp_stock)\n",
    "tmp_stock = get_ymt_date(tmp_stock)\n",
    "us_date_list = list(tmp_stock['ymd_time'])\n",
    "\n",
    "hk_date_list, us_date_list\n",
    "\n",
    "to_date = \"2022-11-10\"\n",
    "prediction_log = []\n",
    "for to_date in hk_date_list[:10]:\n",
    "    #from_date = str(int(to_date[:4])-1) + to_date[4:]\n",
    "    from_date = previous_date(to_date, 300)\n",
    "    prediction_date_HK = to_date\n",
    "    \n",
    "    day_num = 1\n",
    "    prediction_date_US = previous_date(prediction_date_HK, day_num)\n",
    "    while prediction_date_US not in us_date_list:\n",
    "        prediction_date_US = previous_date(prediction_date_HK, day_num)\n",
    "        day_num += 1\n",
    "        if day_num>30:\n",
    "            break\n",
    "\n",
    "    ### base-data \n",
    "    st, et = from_date, to_date\n",
    "\n",
    "    # target\n",
    "    target = '3690.HK'\n",
    "    df_target = get_df_data(target, st, et)\n",
    "    df_target = calculate_daily_change(df_target)\n",
    "    df_target = get_ymt_date(df_target)\n",
    "    features=[\"ymd_time\", \"Close_return\"] # , \"Volume_return\"\n",
    "    hk_dic = date_label(df_target, features)\n",
    "    hk_business_days = list(hk_dic.keys())\n",
    "    df_target\n",
    "\n",
    "    # refer list\n",
    "    refer_list=[\"^IXIC\", \"AAPL\", \"GOOGL\", \"AMZN\", \"BABA\", \"PDD\", \"JD\", \"MPNGY\", \"TME\", \"BIDU\"] # \"^IXIC\", \"^DJI\", \"^GSPC\"\n",
    "    df_reference = get_multiple_stocks(refer_list, st, et)\n",
    "    us_dic = date_features(df_reference, refer_list)\n",
    "    us_business_days = list(us_dic.keys())\n",
    "    df_reference\n",
    "\n",
    "    # merge\n",
    "    df_merge = merge_features_labels(us_dic, hk_dic, refer_list, target)\n",
    "    df_merge\n",
    "\n",
    "    #\n",
    "    print( \"target: \\t HKT\", df_target.iloc[0]['ymd_time'], df_target.iloc[-1]['ymd_time'] )\n",
    "    print( \"reference: \\t UST\", df_reference.iloc[0]['ymd_time'], df_reference.iloc[-1]['ymd_time'] )\n",
    "    date1, date2 = target+\"_date\", \"refer_date\"\n",
    "    print( \"merge: \\t HKT - UST\", df_merge.iloc[0][date1], df_merge.iloc[0][date2] )\n",
    "    print( \"merge: \\t HKT - UST\", df_merge.iloc[-1][date1], df_merge.iloc[-1][date2] )\n",
    "    print( \"prediction: \\t HKT\", prediction_date_HK, \"\\t according to: \\t UST\", prediction_date_US )\n",
    "\n",
    "\n",
    "    ### refine models\n",
    "    search_parameters = []\n",
    "    sample_number = -1\n",
    "    ran_seed1, ran_seed2 = 6, 9\n",
    "    for ran_seed1 in range(1, 6):\n",
    "        X_data, y_data = sample_dataset(df_merge, ran_seed1, sample_number)\n",
    "        for ran_seed2 in range(5, 10):\n",
    "            X_train, X_test, y_train, y_test = split_dataset(X_data, y_data, ran_seed2)\n",
    "            LR1, score = train_LR_model(X_train, X_test, y_train, y_test)\n",
    "            search_parameters.append( (score, ran_seed1, ran_seed2) )\n",
    "    print(sorted(search_parameters)[-3:])\n",
    "    score, ran_seed1, ran_seed2 = sorted(search_parameters)[-1]\n",
    "\n",
    "\n",
    "    # \n",
    "    # fit model\n",
    "    #sample_number = -1\n",
    "    #ran_seed1, ran_seed2 = 6, 0\n",
    "    X_data, y_data = sample_dataset(df_merge, ran_seed1, sample_number)\n",
    "    X_train, X_test, y_train, y_test = split_dataset(X_data, y_data, ran_seed2)\n",
    "    LR1, score = train_LR_model(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    try:\n",
    "        # predict next day\n",
    "        predict_features = get_features_update('2020-01-01', '2022-12-31', refer_list, prediction_date_US)\n",
    "        rise_or_fall = LR1.predict([predict_features])\n",
    "        prob = LR1.predict_proba([predict_features])\n",
    "        print( \"LR predict today: \", rise_or_fall, prob )\n",
    "\n",
    "        # \n",
    "        pred_signal, real_signal = rise_or_fall[0], search_movement(target, prediction_date_HK)\n",
    "        print(pred_signal, real_signal)\n",
    "        prediction_log.append( (score, pred_signal, real_signal) )\n",
    "    except:\n",
    "        print(prediction_date_US, \" does not exist in US business day\")\n",
    "    print()\n",
    "\n",
    "prediction_log\n",
    "counter = 0\n",
    "for it in prediction_log:\n",
    "    s, p, r = it\n",
    "    if p==r:\n",
    "        counter += 1\n",
    "counter, len(prediction_log), round(counter*100/len(prediction_log), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2116fa67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82787f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "018ffc73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
