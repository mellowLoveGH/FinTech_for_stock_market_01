{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2ovkZe3GgbYF"
      },
      "outputs": [],
      "source": [
        "# predict HK stocks according to US stocks\n",
        "    # there is jet-lag between US stocks and HK stocks\n",
        "    # US stock markets have much influence over HK stock markets\n",
        "    # exploit the information from US stock markets to predict HK stock markets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# base data design: incremental data\n",
        "    # base data: one year ago - last business day (namely, one year until current business day)\n",
        "        # base data: training + testing (75% : 25%)\n",
        "# predict current business day\n",
        "\n",
        "# 1. it means every day the base-data should be updated, \n",
        "        # remove the data of the business day of one year ago\n",
        "        # add  the data of the latest business day\n",
        "    # for example, \n",
        "        # today is 2022-11-18, \n",
        "        # base-data should be (2021-11-18 ~ 2022-11-17) \n",
        "        # use the base-data to train & test model, \n",
        "        # then the model predict today/current business day: rise or fall"
      ],
      "metadata": {
        "id": "FSHVIYTrgslG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance\n",
        "import yfinance as yf # https://pypi.org/project/yfinance/\n",
        "import math\n",
        "### the meaning of prediction about stock market\n",
        "from numpy.core.numeric import ones_like\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiPcmJR9gvi6",
        "outputId": "2f78a7ba-fa17-441d-b766-2ebdfc85fb46"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.87-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.9.1)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 769 kB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.1)\n",
            "Installing collected packages: requests, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed requests-2.28.1 yfinance-0.1.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_once():\n",
        "    us_stock_ticker = [\"^IXIC\", \"AAPL\", \"GOOGL\", \"AMZN\", \"MSFT\", \"BABA\", \"PDD\", \"JD\", \"NTES\", \"BIDU\", \"MPNGY\", \"NIO\", \"TCOM\", \"LI\", \"ZTO\", \"TME\", \"XPEV\"]\n",
        "    hk_stock_ticker = [\"9988.HK\", \"3690.HK\", \"0700.HK\", \"9618.HK\", \"0981.HK\", \"9999.HK\", \"1810.HK\", \"1024.HK\", \"9888.HK\", \"2015.HK\", \"9866.HK\"]\n",
        "    ticker_list = us_stock_ticker+hk_stock_ticker\n",
        "    df_dic = {}\n",
        "    start_time=\"2020-01-01\"\n",
        "    end_time=\"2022-12-31\"\n",
        "    for tn in ticker_list:\n",
        "        df_data = yf.download(tickers=tn, start=start_time, end=end_time) \n",
        "        df_dic[tn] = df_data\n",
        "    return df_dic\n",
        "\n",
        "def search_stock(df_dic, tn, st, et):\n",
        "    tmp_df = df_dic[tn].copy()\n",
        "    tmp_df['ymd_time'] = tmp_df.index\n",
        "    tmp_df[\"ymd_time\"] = tmp_df[\"ymd_time\"].astype(str)\n",
        "    tmp_df[\"ymd_time\"] = tmp_df[\"ymd_time\"].str.slice(0,10)\n",
        "    tmp_df[\"date_num\"] = tmp_df[\"ymd_time\"].str.slice(0,4) + tmp_df[\"ymd_time\"].str.slice(5,7) + tmp_df[\"ymd_time\"].str.slice(8,10)\n",
        "    tmp_df[\"date_num\"] = tmp_df[\"date_num\"].astype(int)\n",
        "    stn = int(st[:4] + st[5:7] + st[8:10])\n",
        "    etn = int(et[:4] + et[5:7] + et[8:10])\n",
        "    #print(stn, etn)\n",
        "    tmp_df = tmp_df[ tmp_df[\"date_num\"]>=stn]\n",
        "    tmp_df = tmp_df[ tmp_df[\"date_num\"]<etn]\n",
        "    del tmp_df[\"ymd_time\"]\n",
        "    del tmp_df[\"date_num\"]\n",
        "    return tmp_df\n",
        "\n",
        "df_dic = None\n",
        "if df_dic is None:\n",
        "    df_dic = get_data_once()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lS6K3Augzi4",
        "outputId": "2c5ba343-6b6e-42d9-d2c0-7dc7e12a4580"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get data by ticker-name, start-time & end-time\n",
        "def get_df_data(ticker_name=\"AAPL\", start_time=\"2022-01-01\", end_time=\"2022-10-09\"):\n",
        "  #df_data = yf.download(tickers=ticker_name, start=start_time, end=end_time) \n",
        "  df_data = search_stock(df_dic, ticker_name, start_time, end_time)\n",
        "  return df_data\n",
        "\n",
        "# calculate the daily return by (current_index - previous_index) / previous_index\n",
        "def calculate_daily_return(df_data, OHLC_index=\"Close\"):\n",
        "  name1 = OHLC_index+\"_previous\"\n",
        "  df_data[name1] = df_data[OHLC_index].shift(1)\n",
        "  name2 = OHLC_index+\"_delta\"\n",
        "  df_data[name2] = df_data[OHLC_index] - df_data[name1]\n",
        "  name3 = OHLC_index+\"_return\"\n",
        "  df_data[name3] = df_data[name2] / df_data[name1]\n",
        "  del df_data[name1]\n",
        "  del df_data[name2]\n",
        "  new_feature = name3\n",
        "  return df_data #, new_feature\n",
        "\n",
        "# calculate the daily change of points & volumes\n",
        "    # by (current_index - previous_index) / previous_index\n",
        "    # by (current_volume - previous_volume) / previous_volume\n",
        "def calculate_daily_change(df_data):\n",
        "  # , OHLC_index=\"Close\"\n",
        "  df_data = calculate_daily_return(df_data, \"Close\")\n",
        "  df_data = calculate_daily_return(df_data, \"Volume\")\n",
        "  return df_data #, new_feature\n",
        "\n",
        "\"\"\"# convert the time to be string type: yyyy-mm-dd\n",
        "def get_ymt_date(df_data):\n",
        "  df_data[\"ymd_time\"] = df_data.index\n",
        "  df_data[\"ymd_time\"] = df_data[\"ymd_time\"].astype(str)\n",
        "  df_data[\"ymd_time\"] = df_data[\"ymd_time\"].str.slice(0,10)\n",
        "  return df_data\"\"\"\n",
        "\n",
        "# convert the time to be string type: yyyy-mm-dd\n",
        "  # get month number & week number\n",
        "def get_ymt_date(df_data):\n",
        "  df_data[\"day_week\"] = df_data.index.dayofweek\n",
        "  df_data[\"ymd_time\"] = df_data.index\n",
        "  df_data[\"ymd_time\"] = df_data[\"ymd_time\"].astype(str)\n",
        "  df_data[\"ymd_time\"] = df_data[\"ymd_time\"].str.slice(0,10)\n",
        "  # month\n",
        "  df_data[\"monthNumber\"] = df_data[\"ymd_time\"].str.slice(5,7)\n",
        "  df_data[\"monthNumber\"] = df_data[\"monthNumber\"].astype(int)\n",
        "  # week\n",
        "  df_data['ymd_time'] = pd.to_datetime(df_data['ymd_time'], errors ='coerce')\n",
        "  df_data['weekNumber'] = df_data['ymd_time'].dt.isocalendar().week\n",
        "  #\n",
        "  df_data[\"ymd_time\"] = df_data.index\n",
        "  df_data[\"ymd_time\"] = df_data[\"ymd_time\"].astype(str)\n",
        "  df_data[\"ymd_time\"] = df_data[\"ymd_time\"].str.slice(0,10)\n",
        "  return df_data\n",
        "\n",
        "# convert dataframe to dict-type data\n",
        "    # key: date time\n",
        "    # value: features such as Close_return & Volume_return\n",
        "def date_features_dict(df_data, features=[\"ymd_time\", \"Close_return\", \"Volume_return\"]):\n",
        "    tmp_df = df_data[features].copy()\n",
        "    date_list = list(tmp_df[\"ymd_time\"])\n",
        "    close_return_list = list(tmp_df[\"Close_return\"])\n",
        "    volume_return_list = list(tmp_df[\"Volume_return\"])\n",
        "    dic = {}\n",
        "    ii = 0\n",
        "    while ii<len(tmp_df):\n",
        "        d, cr, vr = date_list[ii], close_return_list[ii], volume_return_list[ii]\n",
        "        dic[d] = [cr, vr]\n",
        "        ii += 1\n",
        "    return dic\n",
        "\n",
        "# get latest US stock data to predict HK stock\n",
        "def get_multiple_stocks(refer_list, st, et):\n",
        "    df_reference = pd.DataFrame()\n",
        "    for tn in refer_list:\n",
        "        tmp_df = get_df_data(tn, st, et)\n",
        "        tmp_df = calculate_daily_change(tmp_df)\n",
        "        tmp_df = get_ymt_date(tmp_df)\n",
        "        df_reference['ymd_time'] = tmp_df['ymd_time']\n",
        "        df_reference[tn+\"_Close_return\"] = tmp_df[ 'Close_return' ]\n",
        "        df_reference[tn+\"_Volume_return\"] = tmp_df[ 'Volume_return' ]\n",
        "    return df_reference\n",
        "\n",
        "# get label\n",
        "def date_label(df_target, features):\n",
        "    tmp_df = df_target[features].copy()\n",
        "    date_list = list(tmp_df[\"ymd_time\"])\n",
        "    close_return_list = list(tmp_df[\"Close_return\"])\n",
        "    dic = {}\n",
        "    ii = 0\n",
        "    while ii<len(tmp_df):\n",
        "        d, cr = date_list[ii], close_return_list[ii]\n",
        "        if cr>0:\n",
        "            dic[d] = 1\n",
        "        else:\n",
        "            dic[d] = 0\n",
        "        ii += 1\n",
        "    return dic\n",
        "\n",
        "# get features\n",
        "def date_features(df_reference, refer_list):\n",
        "    new_refer_list = [\"ymd_time\"]\n",
        "    for tn in refer_list:\n",
        "        new_refer_list.append(tn + \"_Close_return\")\n",
        "        new_refer_list.append(tn + \"_Volume_return\")\n",
        "    tmp_df = df_reference[new_refer_list].copy()\n",
        "    dic = {}\n",
        "    ii = 0\n",
        "    while ii<len(tmp_df):\n",
        "        row = tmp_df.iloc[ii]\n",
        "        ymd_time = row['ymd_time']\n",
        "        features = []\n",
        "        for tn in new_refer_list[1:]:\n",
        "            features.append( row[tn] )\n",
        "        dic[ymd_time] = features\n",
        "        ii += 1\n",
        "    return dic\n",
        "\n",
        "# get date before today by n days\n",
        "def previous_date(current, days_num=1):\n",
        "    current = datetime.datetime.strptime(current, \"%Y-%m-%d\").date() # %H:%M:%S\n",
        "    previous = current - datetime.timedelta(days=days_num)\n",
        "    return str(previous)\n",
        "\n",
        "# get date after today by n days\n",
        "def next_date(current, days_num=1):\n",
        "    current = datetime.datetime.strptime(current, \"%Y-%m-%d\").date() # %H:%M:%S\n",
        "    next_date = current + datetime.timedelta(days=days_num)\n",
        "    return str(next_date)\n",
        "\n",
        "# search previous business day in US stock market\n",
        "    # according to business day in HK stock market\n",
        "def last_US_day(HK_day, us_business_days):\n",
        "    for days_num in range(1, 30):\n",
        "        US_day = previous_date(HK_day, days_num)\n",
        "        if US_day in us_business_days:\n",
        "            return US_day\n",
        "    return HK_day\n",
        "\n",
        "# \n",
        "\n",
        "# \n",
        "def merge_features_labels(us_dic, hk_dic, refer_list, target, week_info, hk_date_list):\n",
        "    xy_data = []\n",
        "    prev_day = 5\n",
        "    for HK_day, label in hk_dic.items():\n",
        "        US_day = last_US_day(HK_day, us_business_days)\n",
        "        if HK_day == US_day:\n",
        "            continue\n",
        "        features = us_dic[US_day]\n",
        "        row = [HK_day, label, US_day] + features\n",
        "        # week info\n",
        "        wd = datetime.datetime.strptime(HK_day, \"%Y-%m-%d\").weekday()\n",
        "        row = row + week_info[wd]\n",
        "        # previous trend\n",
        "        previous_trend = get_previous_business_day(HK_day, hk_date_list, prev_day)\n",
        "        for pt in previous_trend:\n",
        "          close = search_movement(target, pt)\n",
        "          #print(pt, close)\n",
        "          row.append( close )\n",
        "        xy_data.append( row )\n",
        "    # X, y = [], []\n",
        "    cols = []\n",
        "    cols.append(target+\"_date\")\n",
        "    cols.append(\"label\")\n",
        "    cols.append(\"refer_date\")\n",
        "    for tn in refer_list:\n",
        "        cols.append(tn + \"_Close_return\")\n",
        "        cols.append(tn + \"_Volume_return\")\n",
        "    cols.append(\"fall_ratio\")\n",
        "    cols.append(\"rise_ratio\")\n",
        "    for ind in range(prev_day):\n",
        "      cols.append(\"previous\"+str(ind+1))\n",
        "    df = pd.DataFrame(xy_data, columns = cols)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def scale_list_values(tmp_list):\n",
        "  tmp = []\n",
        "  for it in tmp_list:\n",
        "    tmp.append(it*100)\n",
        "  return tmp\n",
        "\n",
        "\n",
        "# get data-sets for training & testing models from dataframe\n",
        "def dataframe_xy(df_data):\n",
        "    X, y = [], []\n",
        "    for i in range(len(df_data)):\n",
        "        row = list( df_data.iloc[i] )\n",
        "        [HK_day, label, US_day] = row[:3]\n",
        "        features = row[3:]\n",
        "        #\n",
        "        fg = False\n",
        "        for v in features:\n",
        "            if math.isnan(v):\n",
        "                fg = True\n",
        "                break\n",
        "        if fg:\n",
        "            continue\n",
        "        #\n",
        "        X.append( scale_list_values(features) )\n",
        "        y.append(label)\n",
        "    return X, y\n",
        "\n",
        "# sample data for training & testing model\n",
        "def sample_dataset(df_data, ran_seed, sample_number=-1):\n",
        "    # balance the positive and negative samples\n",
        "    positive_df = df_data[ df_data['label']==1 ].copy()\n",
        "    negative_df = df_data[ df_data['label']==0 ].copy()\n",
        "    positive_df = positive_df.dropna()\n",
        "    negative_df = negative_df.dropna()\n",
        "    #print( \"business days: \", len(df_data), \"rise vs fall: \", len(positive_df), len(negative_df) )\n",
        "    if sample_number==-1:\n",
        "        sample_number = min( len(positive_df), len(negative_df) )\n",
        "    X_pos_data, y_pos_data = dataframe_xy(positive_df.sample(n=sample_number, random_state=ran_seed))\n",
        "    X_neg_data, y_neg_data = dataframe_xy(negative_df.sample(n=sample_number, random_state=ran_seed))\n",
        "    X_data = X_pos_data + X_neg_data\n",
        "    y_data = y_pos_data + y_neg_data\n",
        "    #print( \"sampled business days: \", len(X_data), \"rise vs fall: \", len(X_pos_data), len(X_neg_data) )\n",
        "    return X_data, y_data\n",
        "\n",
        "# data-set split and train models\n",
        "def split_dataset(X_data, y_data, ran_seed):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.25, random_state=ran_seed, shuffle=True)\n",
        "    #print( \"training data: \", len(X_train), len(y_train) )\n",
        "    #print( \"testing data: \", len(X_test), len(y_test) )\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# train LR model\n",
        "def train_LR_model(X_train, X_test, y_train, y_test):    \n",
        "    # LR\n",
        "    LR1 = LogisticRegression()\n",
        "    LR1.fit(X_train, y_train)\n",
        "    y_pred = LR1.predict(X_test)\n",
        "    score = LR1.score(X_test, y_test)\n",
        "    #print(classification_report(y_test, y_pred))\n",
        "    #print(\"LR\", score)    \n",
        "    return LR1, score\n",
        "\n",
        "# train SVM model\n",
        "def train_SVM_model(X_train, X_test, y_train, y_test):\n",
        "    # SVM\n",
        "    SVM1 = svm.SVC(kernel='linear', probability=True)  # solver='lbfgs', , max_iter=1000 * 1000 * 20\n",
        "    SVM1.fit(X_train, y_train)\n",
        "    y_pred = SVM1.predict(X_test)\n",
        "    score = SVM1.score(X_test, y_test)\n",
        "    #print(classification_report(y_test, y_pred))\n",
        "    #print(\"SVM\", score)\n",
        "    return SVM1, score\n",
        "\n",
        "# train RF model\n",
        "def train_RF_model(X_train, X_test, y_train, y_test, ran_seed=0):\n",
        "    # RF\n",
        "    RF1=RandomForestClassifier(n_estimators=100, random_state=ran_seed)\n",
        "    RF1.fit(X_train, y_train)\n",
        "    y_pred = RF1.predict(X_test)\n",
        "    score = RF1.score(X_test, y_test)\n",
        "    #print(classification_report(y_test, y_pred))\n",
        "    #print(\"RF\", score)\n",
        "    return RF1, score\n",
        "\n",
        "def train_RF_model_update(X_train, X_test, y_train, y_test):\n",
        "  RF1, score = None, 0\n",
        "  for i in range(10):\n",
        "    tmp1, tmp2 = train_RF_model(X_train, X_test, y_train, y_test, i)\n",
        "    if tmp2>score:\n",
        "      RF1, score = tmp1, tmp2\n",
        "  return RF1, score\n",
        "\n",
        "\n",
        "#\n",
        "def get_features(st, et, refer_list, ind):\n",
        "    df_reference = get_multiple_stocks(refer_list, st, et)\n",
        "    features = []\n",
        "    for tn in refer_list:\n",
        "        date_time = list(df_reference.index)[ind]\n",
        "        close_point = list(df_reference[ tn+\"_Close_return\" ])[ind]\n",
        "        volume_point = list(df_reference[tn+\"_Volume_return\" ])[ind]\n",
        "        print(\"date_time:\", date_time, tn, close_point*100, volume_point*100)\n",
        "        features.append( close_point )\n",
        "        features.append( volume_point )\n",
        "    return features\n",
        "\n",
        "#\n",
        "def get_features_update(st, et, target, refer_list, which_date, HK_day, week_info, hk_date_list):\n",
        "    df_reference = get_multiple_stocks(refer_list, st, et)\n",
        "    df_reference = df_reference[ df_reference['ymd_time']==which_date ]\n",
        "    #print(df_reference)\n",
        "    ind = -1\n",
        "    features = []\n",
        "    for tn in refer_list:\n",
        "        date_time = list(df_reference.index)[ind]\n",
        "        close_point = list(df_reference[ tn+\"_Close_return\" ])[ind]\n",
        "        volume_point = list(df_reference[tn+\"_Volume_return\" ])[ind]\n",
        "        print(\"date_time: \", str(date_time)[:10], tn, close_point*100, volume_point*100)\n",
        "        features.append( close_point )\n",
        "        features.append( volume_point )\n",
        "    #\n",
        "    wd = datetime.datetime.strptime(HK_day, \"%Y-%m-%d\").weekday()\n",
        "    features = features + week_info[wd]\n",
        "    print(\"date_time: \", HK_day, \"fall_ratio\", week_info[wd][0])\n",
        "    print(\"date_time: \", HK_day, \"rise_ratio\", week_info[wd][1])\n",
        "    #\n",
        "    prev_day = 5\n",
        "    previous_trend = get_previous_business_day(HK_day, hk_date_list, prev_day)\n",
        "    for pt in previous_trend:\n",
        "      close = search_movement(target, pt)\n",
        "      print(\"date_time: \", pt, \"trend\", close*100)\n",
        "      features.append( close*100 )\n",
        "    return features\n",
        "\n",
        "# \n",
        "def search_movement(target, prediction_date_HK):\n",
        "    dt1, dt2 = previous_date(prediction_date_HK, 10), next_date(prediction_date_HK, 10)\n",
        "    df_data = search_stock(df_dic, target, dt1, dt2)\n",
        "    df_data = calculate_daily_change(df_data)\n",
        "    df_data = get_ymt_date(df_data)\n",
        "    df_data = df_data[df_data['ymd_time']==prediction_date_HK]\n",
        "    Close_return = df_data.iloc[-1]['Close_return']\n",
        "    return Close_return\n",
        "\n",
        "def weekday_ratio(df_data):\n",
        "  dic = {0:[0,0], 1:[0,0], 2:[0,0], 3:[0,0], 4:[0,0], 5:[0,0], 6:[0,0]}\n",
        "  L = len(df_data)\n",
        "  i = 0\n",
        "  while i<L:\n",
        "    row = df_data.iloc[i]\n",
        "    Close_return = row['Close_return']\n",
        "    day_week = row['day_week']\n",
        "    if Close_return>0:\n",
        "      dic[day_week][1] += 1\n",
        "    else:\n",
        "      dic[day_week][0] += 1\n",
        "    i += 1\n",
        "  #\n",
        "  tmp = {}\n",
        "  for k, v in dic.items():\n",
        "    [f, r] = v\n",
        "    p0 = (f+1)/(f+1+r+1) #round((f+1)/(f+1+r+1)*100, 2)\n",
        "    p1 = (r+1)/(f+1+r+1) # round((r+1)/(f+1+r+1)*100, 2)\n",
        "    tmp[k] = [ p0, p1 ]\n",
        "  return tmp\n",
        "\n",
        "#\n",
        "def get_previous_business_day(current, date_list, num):\n",
        "  tmp_list = []\n",
        "  day_num = 1\n",
        "  while len(tmp_list)!=num:\n",
        "    pv = previous_date(current, day_num)\n",
        "    if pv in date_list:\n",
        "      tmp_list.append(pv)\n",
        "    day_num += 1\n",
        "  return tmp_list\n",
        "\n",
        "#\n",
        "tmp_stock = get_df_data('9988.HK', \"2020-01-01\", \"2022-12-31\")\n",
        "tmp_stock = calculate_daily_change(tmp_stock)\n",
        "tmp_stock = get_ymt_date(tmp_stock)\n",
        "hk_date_list = list(tmp_stock['ymd_time'])\n",
        "\n",
        "tmp_stock = get_df_data('AAPL', \"2020-01-01\", \"2022-12-31\")\n",
        "tmp_stock = calculate_daily_change(tmp_stock)\n",
        "tmp_stock = get_ymt_date(tmp_stock)\n",
        "us_date_list = list(tmp_stock['ymd_time'])\n",
        "\n",
        "hk_date_list, us_date_list\n",
        "print()\n",
        "\n",
        "# get_df_data('3690.HK', \"2022-01-01\", \"2022-12-31\").tail(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogwsKbVXg30O",
        "outputId": "b526ce69-0b08-4b5c-be60-df7095cfc7d6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_date = \"2022-11-21\"\n",
        "prediction_log = []\n",
        "for to_date in hk_date_list[-1:]:\n",
        "    from_date = previous_date(to_date, 365)\n",
        "    prediction_date_HK = to_date\n",
        "    \n",
        "    day_num = 1\n",
        "    prediction_date_US = previous_date(prediction_date_HK, day_num)\n",
        "    while prediction_date_US not in us_date_list:\n",
        "        prediction_date_US = previous_date(prediction_date_HK, day_num)\n",
        "        day_num += 1\n",
        "        if day_num>30:\n",
        "            break\n",
        "\n",
        "    ### base-data \n",
        "    st, et = from_date, to_date\n",
        "\n",
        "    # target\n",
        "    target = '9988.HK'\n",
        "    df_target = get_df_data(target, st, et)\n",
        "    df_target = calculate_daily_change(df_target)\n",
        "    df_target = get_ymt_date(df_target)\n",
        "    features=[\"ymd_time\", \"Close_return\"] # , \"Volume_return\"\n",
        "    hk_dic = date_label(df_target, features)\n",
        "    hk_business_days = list(hk_dic.keys())\n",
        "    df_target\n",
        "\n",
        "    week_info = weekday_ratio(df_target)\n",
        "    print(\"week_info: \", week_info)\n",
        "\n",
        "    # refer list\n",
        "    refer_list=[\"^IXIC\", \"AAPL\", \"GOOGL\", \"AMZN\", \"BABA\", \"PDD\", \"JD\", \"MPNGY\", \"TME\", \"BIDU\"] # \"^IXIC\", \"^DJI\", \"^GSPC\"\n",
        "    df_reference = get_multiple_stocks(refer_list, st, et)\n",
        "    us_dic = date_features(df_reference, refer_list)\n",
        "    us_business_days = list(us_dic.keys())\n",
        "    df_reference\n",
        "\n",
        "    # merge\n",
        "    df_merge = merge_features_labels(us_dic, hk_dic, refer_list, target, week_info, hk_date_list)\n",
        "    df_merge\n",
        "\n",
        "    #\n",
        "    print( \"target: \\t HKT\", df_target.iloc[0]['ymd_time'], df_target.iloc[-1]['ymd_time'] )\n",
        "    print( \"reference: \\t UST\", df_reference.iloc[0]['ymd_time'], df_reference.iloc[-1]['ymd_time'] )\n",
        "    date1, date2 = target+\"_date\", \"refer_date\"\n",
        "    print( \"merge: \\t HKT - UST\", df_merge.iloc[0][date1], df_merge.iloc[0][date2] )\n",
        "    print( \"merge: \\t HKT - UST\", df_merge.iloc[-1][date1], df_merge.iloc[-1][date2] )\n",
        "    print( \"prediction: \\t HKT\", prediction_date_HK, \"\\t according to: \\t UST\", prediction_date_US )\n",
        "\n",
        "\n",
        "    ### refine models\n",
        "    search_parameters = {\"LR\":[], \"SVM\":[], \"RF\":[]}\n",
        "    sample_number = -1\n",
        "    ran_seed1, ran_seed2 = 6, 9\n",
        "    for ran_seed1 in range(0, 10):\n",
        "        X_data, y_data = sample_dataset(df_merge, ran_seed1, sample_number)\n",
        "        for ran_seed2 in range(0, 10):\n",
        "            X_train, X_test, y_train, y_test = split_dataset(X_data, y_data, ran_seed2)\n",
        "            #\n",
        "            LR1, score = train_LR_model(X_train, X_test, y_train, y_test)\n",
        "            search_parameters[\"LR\"].append( (score, ran_seed1, ran_seed2) )\n",
        "            SVM1, score = train_SVM_model(X_train, X_test, y_train, y_test)\n",
        "            search_parameters[\"SVM\"].append( (score, ran_seed1, ran_seed2) )\n",
        "            RF1, score = train_RF_model_update(X_train, X_test, y_train, y_test)\n",
        "            search_parameters[\"RF\"].append( (score, ran_seed1, ran_seed2) )\n",
        "        print( ran_seed1, (ran_seed1*10+10), \"%\" )\n",
        "    print(\"LR: \\t\", sorted(search_parameters[\"LR\"])[-3:])\n",
        "    print(\"SVM: \\t\", sorted(search_parameters[\"SVM\"])[-3:])\n",
        "    print(\"RF: \\t\", sorted(search_parameters[\"RF\"])[-3:])\n",
        "\n",
        "    # \n",
        "    # fit model\n",
        "    #sample_number = -1\n",
        "    #ran_seed1, ran_seed2 = 6, 0\n",
        "    score, ran_seed1, ran_seed2 = sorted(search_parameters[\"LR\"])[-1]\n",
        "    X_data, y_data = sample_dataset(df_merge, ran_seed1, sample_number)\n",
        "    X_train, X_test, y_train, y_test = split_dataset(X_data, y_data, ran_seed2)\n",
        "    LR1, score = train_LR_model(X_train, X_test, y_train, y_test)\n",
        "    y_pred = LR1.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    score, ran_seed1, ran_seed2 = sorted(search_parameters[\"SVM\"])[-1]\n",
        "    X_data, y_data = sample_dataset(df_merge, ran_seed1, sample_number)\n",
        "    X_train, X_test, y_train, y_test = split_dataset(X_data, y_data, ran_seed2)\n",
        "    SVM1, score = train_SVM_model(X_train, X_test, y_train, y_test)\n",
        "    y_pred = SVM1.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    score, ran_seed1, ran_seed2 = sorted(search_parameters[\"RF\"])[-1]\n",
        "    X_data, y_data = sample_dataset(df_merge, ran_seed1, sample_number)\n",
        "    X_train, X_test, y_train, y_test = split_dataset(X_data, y_data, ran_seed2)\n",
        "    RF1, score = train_RF_model_update(X_train, X_test, y_train, y_test)\n",
        "    y_pred = RF1.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    try:\n",
        "        # predict next day\n",
        "        predict_features = get_features_update('2020-01-01', '2022-12-31', target, refer_list, prediction_date_US, prediction_date_HK, week_info, hk_date_list)\n",
        "        \n",
        "        # \n",
        "        rise_or_fall1 = LR1.predict([predict_features])\n",
        "        prob = LR1.predict_proba([predict_features])\n",
        "        print( \"LR predict today: \", rise_or_fall1, prob )\n",
        "        rise_or_fall2 = SVM1.predict([predict_features])\n",
        "        prob = SVM1.predict_proba([predict_features])\n",
        "        print( \"SVM predict today: \", rise_or_fall2, prob )\n",
        "        rise_or_fall3 = RF1.predict([predict_features])\n",
        "        prob = RF1.predict_proba([predict_features])\n",
        "        print( \"RF predict today: \", rise_or_fall3, prob )\n",
        "\n",
        "        # \n",
        "        real_signal = \"unknown\"\n",
        "        try:\n",
        "          real_signal = search_movement(target, prediction_date_HK)\n",
        "        except:\n",
        "          real_signal = \"unknown\"\n",
        "          print( \"there is no such real label: for HKT\", prediction_date_HK )\n",
        "        print(rise_or_fall1[0], rise_or_fall2[0], rise_or_fall3[0], \" vs \", real_signal)\n",
        "        prediction_log.append( (rise_or_fall1[0], rise_or_fall2[0], rise_or_fall3[0], real_signal) )\n",
        "    except:\n",
        "        print(prediction_date_US, \" does not exist in US business day\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvWkbWNMhkBC",
        "outputId": "a4cfdc07-1081-4b11-c0d7-9d806e9dea6d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "week_info:  {0: [0.7142857142857143, 0.2857142857142857], 1: [0.5490196078431373, 0.45098039215686275], 2: [0.6226415094339622, 0.37735849056603776], 3: [0.6296296296296297, 0.37037037037037035], 4: [0.5294117647058824, 0.47058823529411764], 5: [0.5, 0.5], 6: [0.5, 0.5]}\n",
            "target: \t HKT 2021-11-18 2022-11-17\n",
            "reference: \t UST 2021-11-18 2022-11-17\n",
            "merge: \t HKT - UST 2021-11-19 2021-11-18\n",
            "merge: \t HKT - UST 2022-11-17 2022-11-16\n",
            "prediction: \t HKT 2022-11-18 \t according to: \t UST 2022-11-17\n",
            "0 10 %\n",
            "1 20 %\n",
            "2 30 %\n",
            "3 40 %\n",
            "4 50 %\n",
            "5 60 %\n",
            "6 70 %\n",
            "7 80 %\n",
            "8 90 %\n",
            "9 100 %\n",
            "LR: \t [(0.8125, 0, 7), (0.8333333333333334, 1, 7), (0.8541666666666666, 8, 5)]\n",
            "SVM: \t [(0.7916666666666666, 8, 5), (0.7916666666666666, 9, 3), (0.8125, 1, 7)]\n",
            "RF: \t [(0.7916666666666666, 7, 7), (0.8125, 6, 7), (0.8125, 8, 5)]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85        22\n",
            "           1       0.91      0.81      0.86        26\n",
            "\n",
            "    accuracy                           0.85        48\n",
            "   macro avg       0.86      0.86      0.85        48\n",
            "weighted avg       0.86      0.85      0.85        48\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83        26\n",
            "           1       0.81      0.77      0.79        22\n",
            "\n",
            "    accuracy                           0.81        48\n",
            "   macro avg       0.81      0.81      0.81        48\n",
            "weighted avg       0.81      0.81      0.81        48\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.95      0.82        22\n",
            "           1       0.95      0.69      0.80        26\n",
            "\n",
            "    accuracy                           0.81        48\n",
            "   macro avg       0.84      0.82      0.81        48\n",
            "weighted avg       0.85      0.81      0.81        48\n",
            "\n",
            "date_time:  2022-11-17 ^IXIC -0.34604230432442423 -5.0342515795419605\n",
            "date_time:  2022-11-17 AAPL 1.297135574741765 25.181451393138715\n",
            "date_time:  2022-11-17 GOOGL -0.49569840296741385 -10.488160191306022\n",
            "date_time:  2022-11-17 AMZN -2.33731899533006 -6.0720473676312094\n",
            "date_time:  2022-11-17 BABA 7.8045012644725205 132.94628209315508\n",
            "date_time:  2022-11-17 PDD 4.425703968640432 70.43783565565246\n",
            "date_time:  2022-11-17 JD 7.534116008299195 123.2392185772208\n",
            "date_time:  2022-11-17 MPNGY 4.81849315473527 27.217214306484443\n",
            "date_time:  2022-11-17 TME 13.0929802602988 27.575815578819245\n",
            "date_time:  2022-11-17 BIDU 5.097627262326847 21.94250665588245\n",
            "date_time:  2022-11-18 fall_ratio 0.5294117647058824\n",
            "date_time:  2022-11-18 rise_ratio 0.47058823529411764\n",
            "date_time:  2022-11-17 trend -0.6979733889052729\n",
            "date_time:  2022-11-16 trend -0.12674077590264002\n",
            "date_time:  2022-11-15 trend 11.0485547318029\n",
            "date_time:  2022-11-14 trend 0.35310732941245687\n",
            "date_time:  2022-11-11 trend 12.380957225012402\n",
            "LR predict today:  [0] [[0.53490511 0.46509489]]\n",
            "SVM predict today:  [0] [[0.51966564 0.48033436]]\n",
            "RF predict today:  [0] [[0.75 0.25]]\n",
            "0 0 0  vs  0.02172520061651358\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_log\n",
        "counter = 0\n",
        "for it in prediction_log:\n",
        "    p1, p2, p3, r = it\n",
        "    if r>0:\n",
        "      r = 1\n",
        "    else:\n",
        "      r = 0\n",
        "    print(p1, p2, p3, \" vs \", r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIdHyBKxO-Cm",
        "outputId": "6cd8b4aa-42c9-4cde-e756-dad2f8cc6457"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0 0  vs  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LnnPDJXDiSgH"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}